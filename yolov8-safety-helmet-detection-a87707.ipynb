{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5048288,"sourceType":"datasetVersion","datasetId":2919095},{"sourceId":7644869,"sourceType":"datasetVersion","datasetId":4456085},{"sourceId":7646340,"sourceType":"datasetVersion","datasetId":4457015}],"dockerImageVersionId":30408,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"padding: 25px 25px; background-color: #F5B041; font-family: Sans-Serif; color:black; text-align: center\">\nProject: Safety Helmet Detection</h1>","metadata":{}},{"cell_type":"markdown","source":"<h2 style=\"padding: 12px 12px; background-color: #F5B041; font-family: Sans-Serif; color:black\">\nOverview</h2>","metadata":{}},{"cell_type":"markdown","source":"Goal of the project is to detect the presence of people and safety helmets thus improving work safety. ","metadata":{}},{"cell_type":"markdown","source":"<h2 style=\"padding: 12px 12px; background-color: #F5B041; font-family: Sans-Serif; color:black\">\nTable of contents</h2>","metadata":{}},{"cell_type":"markdown","source":"1. [Data Description](#data-description) \n2. [Import modules](#import-modules)\n3. [Configuration](#configuration)\n4. [Data Exploration](#data-exploration)\n5. [Train](#train)\n6. [Test](#test)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"data-description\"></a>\n<h2 style=\"padding: 12px 12px; background-color: #F5B041; font-family: Sans-Serif; color:black\">\nData description</h2>","metadata":{}},{"cell_type":"markdown","source":"- The dataset is a great collection of images, since the labels are in the following format: 'Hardhat', 'Mask', 'NO-Hardhat', 'NO-Mask', 'NO-Safety Vest', 'Person', 'Safety Cone', 'Safety Vest', 'machinery', 'vehicle'\n\n- **Quick Summary**\n    - Number of classes: 10\n    - Label Annotation: YOLO format (.txt)\n    - Metadata: metadata.csv and count.csv provides information about the dataset and train-val-test count information.\n    - PPE Class Map: {0: 'Hardhat', 1: 'Mask', 2: 'NO-Hardhat', 3: 'NO-Mask', 4: 'NO-Safety Vest', 5: 'Person', 6: 'Safety Cone', 7: 'Safety Vest', 8: 'machinery', 9: 'vehicle'}\n    - Difficulty: This is a beginner-friendly dataset on multi-class classification, object detection, and tracking. Annotations are in YoloV8 format. The splits are given in the dataset folder itself with metadata, so anyone can use this data to run models and produce results.\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"import-modules\"></a>\n<h2 style=\"padding: 12px 12px; background-color: #F5B041; font-family: Sans-Serif; color:black\">\nImport modules</h2>","metadata":{}},{"cell_type":"code","source":"pip install ultralytics","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:56:10.699422Z","iopub.execute_input":"2024-02-18T02:56:10.699848Z","iopub.status.idle":"2024-02-18T02:56:22.571428Z","shell.execute_reply.started":"2024-02-18T02:56:10.699812Z","shell.execute_reply":"2024-02-18T02:56:22.570108Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: ultralytics in /opt/conda/lib/python3.7/site-packages (8.0.145)\nRequirement already satisfied: matplotlib>=3.2.2 in /opt/conda/lib/python3.7/site-packages (from ultralytics) (3.5.3)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from ultralytics) (9.4.0)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.7/site-packages (from ultralytics) (4.64.1)\nRequirement already satisfied: torch>=1.7.0 in /opt/conda/lib/python3.7/site-packages (from ultralytics) (1.13.0)\nRequirement already satisfied: torchvision>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from ultralytics) (0.14.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.7/site-packages (from ultralytics) (1.3.5)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.7/site-packages (from ultralytics) (6.0)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from ultralytics) (0.12.2)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.7/site-packages (from ultralytics) (2.28.2)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from ultralytics) (1.7.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.7/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from ultralytics) (4.9.0.80)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2->ultralytics) (23.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2->ultralytics) (4.38.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2->ultralytics) (1.21.6)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.23.0->ultralytics) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.23.0->ultralytics) (1.26.14)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from seaborn>=0.11.0->ultralytics) (4.4.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport warnings\nimport matplotlib.pyplot as plt\nfrom IPython.core.magic import register_line_cell_magic\nimport yaml\nfrom PIL import Image\nimport os\nimport seaborn as sns\nfrom ultralytics import YOLO\nfrom ultralytics import NAS\nfrom matplotlib.patches import Rectangle\nimport glob\nimport cv2\n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:56:22.573578Z","iopub.execute_input":"2024-02-18T02:56:22.573916Z","iopub.status.idle":"2024-02-18T02:56:25.220051Z","shell.execute_reply.started":"2024-02-18T02:56:22.573881Z","shell.execute_reply":"2024-02-18T02:56:25.218754Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"configuration\"></a>\n<h2 style=\"padding: 12px 12px; background-color: #F5B041; font-family: Sans-Serif; color:black\">\nConfiguration</h2>","metadata":{}},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\n\nnp.random.seed(12345)\n\n%matplotlib inline\n\n!wandb disabled","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:56:49.530080Z","iopub.execute_input":"2024-02-18T02:56:49.531756Z","iopub.status.idle":"2024-02-18T02:56:51.957018Z","shell.execute_reply.started":"2024-02-18T02:56:49.531703Z","shell.execute_reply":"2024-02-18T02:56:51.955817Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"W&B disabled.\n","output_type":"stream"}]},{"cell_type":"code","source":"INPUT_DIR = '/kaggle/input/construction-site-safety-image-dataset-roboflow/css-data'\nWORK_DIR = '/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:57:04.619403Z","iopub.execute_input":"2024-02-18T02:57:04.620186Z","iopub.status.idle":"2024-02-18T02:57:04.624795Z","shell.execute_reply.started":"2024-02-18T02:57:04.620144Z","shell.execute_reply":"2024-02-18T02:57:04.623627Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"INPUT_DIR = '/kaggle/input/godsensi/data'\nWORK_DIR = '/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:56:55.810071Z","iopub.execute_input":"2024-02-18T02:56:55.811128Z","iopub.status.idle":"2024-02-18T02:56:55.816412Z","shell.execute_reply.started":"2024-02-18T02:56:55.811079Z","shell.execute_reply":"2024-02-18T02:56:55.815276Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"Data Exploration\"></a>\n<h2 style=\"padding: 12px 12px; background-color: #F5B041; font-family: Sans-Serif; color:black\">\nData Exploration</h2>","metadata":{}},{"cell_type":"markdown","source":"<h4 style=\"border-bottom: 3px solid #FAD7A0; padding: 12px 12px; font-family: Sans-Serif; color:black\">\n<b>Create data YAML file</b></h4>","metadata":{}},{"cell_type":"code","source":"num_classes = 10\nclasses = ['Hardhat', 'Mask', 'NO-Hardhat', 'NO-Mask', 'NO-Safety Vest', 'Person', 'Safety Cone', 'Safety Vest', 'machinery', 'vehicle']","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:57:10.370555Z","iopub.execute_input":"2024-02-18T02:57:10.370952Z","iopub.status.idle":"2024-02-18T02:57:10.376253Z","shell.execute_reply.started":"2024-02-18T02:57:10.370917Z","shell.execute_reply":"2024-02-18T02:57:10.375169Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dict_file = {'train': os.path.join(INPUT_DIR, 'train'),\n             'val': os.path.join(INPUT_DIR, 'valid'),\n             'test': os.path.join(INPUT_DIR, 'test'),\n             'nc': num_classes,\n             'names': classes\n            }\n\nwith open(os.path.join(WORK_DIR, 'data.yaml'), 'w+') as file:\n    yaml.dump(dict_file, file)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:57:14.817658Z","iopub.execute_input":"2024-02-18T02:57:14.818583Z","iopub.status.idle":"2024-02-18T02:57:14.827654Z","shell.execute_reply.started":"2024-02-18T02:57:14.818542Z","shell.execute_reply":"2024-02-18T02:57:14.826475Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"<h4 style=\"border-bottom: 3px solid #FAD7A0; padding: 12px 12px; font-family: Sans-Serif; color:black\">\n<b>Check class balance</b></h4>","metadata":{}},{"cell_type":"code","source":"class_idx = {str(i):classes[i] for i in range(num_classes)}\n\nclass_stat = {}\ndata_len = {}\n\nfor mode in ['train', 'valid', 'test']:\n\n    class_count = {classes[i]:0 for i in range(num_classes)}\n\n    path = os.path.join(INPUT_DIR, mode, 'labels')\n\n    for file in os.listdir(path):\n\n        with open(os.path.join(path, file)) as f:\n            lines = f.readlines()\n\n            for cls in set([line[0] for line in lines]):\n                class_count[class_idx[cls]] += 1\n                \n    data_len[mode] = len(os.listdir(path))\n    class_stat[mode] = class_count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,3, figsize=(15, 5), sharey=True)\n\nfor i, mode in enumerate(['train', 'valid', 'test']):\n    sns.barplot(pd.DataFrame({mode:class_stat[mode]}).T/data_len[mode]*100, ax=ax[i])\n    ax[i].set_title(mode)\n    ax[i].tick_params(rotation=90)\n    ax[i].set_ylabel('Percenatage of classes')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- There is imbalance in classes\n\n\n- Overall class distribution between train, validation and test sets are similar, although validation and test sets have significantly lower percentage of `machinery` class","metadata":{}},{"cell_type":"markdown","source":"<h4 style=\"border-bottom: 3px solid #FAD7A0; padding: 12px 12px; font-family: Sans-Serif; color:black\">\n<b>Check image sizes</b></h4>","metadata":{}},{"cell_type":"code","source":"for mode in ['train', 'valid', 'test']:\n    print(f'\\nImage sizes in {mode} set:\\n')\n    img_size = 0\n    for file in glob.glob(os.path.join(INPUT_DIR, mode, 'images', '*')):\n        image = Image.open(file)\n        if image.size != img_size:\n            print(f'\\t{image.size}')\n            img_size = image.size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- All images have size `640x640`","metadata":{}},{"cell_type":"markdown","source":"<h4 style=\"border-bottom: 3px solid #FAD7A0; padding: 12px 12px; font-family: Sans-Serif; color:black\">\n<b>Check dataset sizes</b></h4>","metadata":{}},{"cell_type":"code","source":"for mode in ['train', 'valid', 'test']:\n    \n    files =  glob.glob(os.path.join(INPUT_DIR, mode, 'images', '*'))\n        \n    print(f'{mode} set size: {len(files)}\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"train\"></a>\n\n<h2 style=\"padding: 12px 12px; background-color: #F5B041; font-family: Sans-Serif; color:black\">\nTrain</h2>","metadata":{}},{"cell_type":"markdown","source":"<h4 style=\"border-bottom: 3px solid #FAD7A0; padding: 12px 12px; font-family: Sans-Serif; color:black\">\n<b>Arguments for training</b></h4>","metadata":{}},{"cell_type":"markdown","source":"- **task**: preform `detect`, `segment` or `classify`\n- **imgsz**: define input image size\n- **batch**: determine batch size\n- **epochs**: define the number of training epochs. (Note: often, 3000+ are common here!)\n- **data**: set the path to our yaml file\n- **mode**: mode - `train`, `val` or `predict`\n- **model**: model to use (could be pre-trained)\n- **name**: result names","metadata":{}},{"cell_type":"markdown","source":"<h4 style=\"border-bottom: 3px solid #FAD7A0; padding: 12px 12px; font-family: Sans-Serif; color:black\">\n<b>Load model<b></h4>","metadata":{}},{"cell_type":"markdown","source":"- Load `pre-trained` YOLO-nano model ","metadata":{}},{"cell_type":"code","source":"import torch\n\n# Load the first YOLO model\nmodel1 = YOLO('yolov8n.pt')\n\n# Load the second YOLO model\nmodel2 = YOLO('yolov8n.pt')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = YOLO('yolov8n.pt')","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:57:27.049626Z","iopub.execute_input":"2024-02-18T02:57:27.050408Z","iopub.status.idle":"2024-02-18T02:57:27.103847Z","shell.execute_reply.started":"2024-02-18T02:57:27.050369Z","shell.execute_reply":"2024-02-18T02:57:27.102915Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"<h4 style=\"border-bottom: 3px solid #FAD7A0; padding: 12px 12px; font-family: Sans-Serif; color:black\">\n<b>Train</b></h4>","metadata":{}},{"cell_type":"code","source":"model.train(data=os.path.join(WORK_DIR,'data.yaml'),\n            task='detect',\n            imgsz=640,\n            epochs=30,\n            batch=32,\n            mode='train',\n            name='yolov8n_v1_train')","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:57:47.799539Z","iopub.execute_input":"2024-02-18T02:57:47.800327Z","iopub.status.idle":"2024-02-18T03:16:57.261320Z","shell.execute_reply.started":"2024-02-18T02:57:47.800287Z","shell.execute_reply":"2024-02-18T03:16:57.259983Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"New https://pypi.org/project/ultralytics/8.1.15 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.145 ðŸš€ Python-3.7.12 torch-1.13.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\nWARNING âš ï¸ Upgrade to torch>=2.0.0 for deterministic training.\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/data.yaml, epochs=30, patience=50, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=yolov8n_v1_train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/yolov8n_v1_train\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/755k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"146ce757055540c7b2c3c00c9d525e86"}},"metadata":{}},{"name":"stderr","text":"Overriding model.yaml nc=80 with nc=10\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.head.Detect           [10, [64, 128, 256]]          \nModel summary: 225 layers, 3012798 parameters, 3012782 gradients\n\nTransferred 319/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/yolov8n_v1_train', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/train/labels... 2605 images, 6 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:13<00:00, 199.11it/s]\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/train/images/004720_jpg.rf.afc486560a4004c7cfd67910af31a29c.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/train/images/construction-813-_jpg.rf.b085952261fd98f2e76b8065de149b5f.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ Cache directory /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/train is not writeable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/valid/labels... 114 images, 10 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<00:00, 192.88it/s]\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ Cache directory /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/valid is not writeable, cache not saved.\nPlotting labels to runs/detect/yolov8n_v1_train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/yolov8n_v1_train\u001b[0m\nStarting training for 30 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/30      6.86G      1.399      3.003      1.496        308        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:36<00:00,  2.26it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.47s/it]\n                   all        114        697      0.421      0.297      0.319      0.133\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/30      6.64G       1.29      1.862      1.437        318        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:35<00:00,  2.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.37it/s]\n                   all        114        697       0.54      0.406       0.43      0.193\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/30      6.33G      1.251      1.657      1.408        198        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:34<00:00,  2.36it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.45it/s]\n                   all        114        697      0.664      0.388      0.433      0.189\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/30      6.16G      1.214      1.555      1.377        290        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:34<00:00,  2.37it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]\n                   all        114        697      0.613      0.473      0.498      0.214\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/30      5.16G      1.192       1.47      1.352        276        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:34<00:00,  2.37it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.69it/s]\n                   all        114        697      0.666      0.457      0.513      0.238\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/30      6.76G      1.165      1.389      1.331        305        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:34<00:00,  2.41it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.50it/s]\n                   all        114        697      0.641      0.494       0.54       0.24\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/30       5.3G       1.15       1.35      1.321        213        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:34<00:00,  2.40it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.56it/s]\n                   all        114        697      0.675      0.459        0.5       0.23\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/30      6.08G       1.12      1.296      1.296        210        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:34<00:00,  2.38it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.66it/s]\n                   all        114        697      0.682      0.563      0.596      0.255\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/30      5.56G      1.116      1.251      1.284        278        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:34<00:00,  2.40it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.45it/s]\n                   all        114        697      0.785      0.553      0.614      0.266\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/30      6.18G      1.095      1.216      1.276        253        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:34<00:00,  2.37it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.18it/s]\n                   all        114        697      0.759      0.542      0.619      0.309\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/30         6G      1.089      1.186      1.267        195        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:34<00:00,  2.37it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.44it/s]\n                   all        114        697      0.762      0.574      0.649       0.31\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/30      5.58G      1.068      1.148      1.253        315        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:34<00:00,  2.39it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.58it/s]\n                   all        114        697      0.757      0.567      0.651      0.339\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/30      6.25G      1.062      1.121      1.243        311        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:33<00:00,  2.42it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.45it/s]\n                   all        114        697      0.806      0.576      0.672       0.34\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/30      5.94G      1.053      1.095      1.232        353        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:33<00:00,  2.45it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.56it/s]\n                   all        114        697      0.745      0.588      0.652      0.312\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/30      6.11G      1.029      1.079      1.233        220        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:33<00:00,  2.47it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.57it/s]\n                   all        114        697      0.792       0.59      0.679       0.35\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      16/30      6.31G      1.038      1.063       1.23        285        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:33<00:00,  2.43it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.64it/s]\n                   all        114        697      0.811      0.605       0.68      0.356\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      17/30      5.86G      1.014      1.031       1.22        291        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:33<00:00,  2.48it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.56it/s]\n                   all        114        697      0.787      0.637      0.694      0.352\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      18/30      5.74G      1.007      1.011      1.213        349        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:32<00:00,  2.49it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.73it/s]\n                   all        114        697      0.782      0.623      0.672      0.327\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      19/30      5.61G     0.9952     0.9941      1.208        276        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:32<00:00,  2.49it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.84it/s]\n                   all        114        697      0.775      0.648      0.702      0.345\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      20/30      5.17G     0.9834     0.9703       1.19        324        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:34<00:00,  2.38it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.49it/s]\n                   all        114        697      0.844      0.643      0.715      0.382\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      21/30       5.2G      1.022     0.9279      1.218        240        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:34<00:00,  2.40it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.58it/s]\n                   all        114        697       0.82      0.644      0.715      0.405\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      22/30      4.62G     0.9928     0.8761      1.201        217        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:30<00:00,  2.68it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.69it/s]\n                   all        114        697      0.845      0.643      0.723      0.391\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      23/30       5.5G     0.9799     0.8464      1.191        181        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:30<00:00,  2.69it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.49it/s]\n                   all        114        697       0.86      0.634      0.723      0.402\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      24/30      5.24G     0.9666     0.8331      1.185        132        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:29<00:00,  2.78it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.66it/s]\n                   all        114        697       0.84      0.647      0.731      0.396\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      25/30      4.84G     0.9459     0.8061      1.168        145        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:29<00:00,  2.80it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.66it/s]\n                   all        114        697      0.881      0.663      0.751      0.408\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      26/30      5.47G     0.9389     0.7962      1.166        146        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:29<00:00,  2.81it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.76it/s]\n                   all        114        697      0.855      0.672      0.744       0.43\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      27/30      5.14G     0.9269     0.7821      1.162        207        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:29<00:00,  2.82it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.61it/s]\n                   all        114        697      0.858      0.675      0.754      0.443\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      28/30      5.29G      0.909     0.7587      1.148        187        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:28<00:00,  2.85it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.64it/s]\n                   all        114        697      0.868      0.684      0.757      0.433\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      29/30      4.88G      0.908     0.7434      1.139        158        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:29<00:00,  2.74it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.67it/s]\n                   all        114        697      0.846      0.692      0.758      0.444\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      30/30      5.45G     0.8932     0.7356      1.135        184        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:29<00:00,  2.74it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.34s/it]\n                   all        114        697      0.838      0.702      0.762      0.439\n\n30 epochs completed in 0.302 hours.\nOptimizer stripped from runs/detect/yolov8n_v1_train/weights/last.pt, 6.2MB\nOptimizer stripped from runs/detect/yolov8n_v1_train/weights/best.pt, 6.2MB\n\nValidating runs/detect/yolov8n_v1_train/weights/best.pt...\nUltralytics YOLOv8.0.145 ðŸš€ Python-3.7.12 torch-1.13.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\nModel summary (fused): 168 layers, 3007598 parameters, 0 gradients\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.09it/s]\n                   all        114        697       0.85      0.687      0.759      0.443\n               Hardhat        114         79      0.934      0.759      0.867      0.542\n                  Mask        114         21      0.944       0.81      0.861      0.576\n            NO-Hardhat        114         69      0.809      0.554      0.634      0.336\n               NO-Mask        114         74      0.809      0.516      0.576      0.243\n        NO-Safety Vest        114        106      0.858      0.571      0.692      0.372\n                Person        114        166      0.863      0.741      0.823      0.493\n           Safety Cone        114         44      0.834      0.841      0.854      0.458\n           Safety Vest        114         41       0.93      0.732      0.849      0.519\n             machinery        114         55      0.864      0.873      0.914      0.585\n               vehicle        114         42      0.655      0.476      0.518       0.31\nSpeed: 1.7ms preprocess, 2.5ms inference, 0.0ms loss, 0.9ms postprocess per image\nResults saved to \u001b[1mruns/detect/yolov8n_v1_train\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a id=\"test\"></a>\n\n<h2 style=\"padding: 12px 12px; background-color: #F5B041; font-family: Sans-Serif; color:black\">\nTest</h2>","metadata":{}},{"cell_type":"markdown","source":"<h4 style=\"border-bottom: 3px solid #FAD7A0; padding: 12px 12px; font-family: Sans-Serif; color:black\">\n<b>Select best model</b></h4>","metadata":{}},{"cell_type":"code","source":"model = YOLO('/kaggle/working/runs/detect/yolov8n_v1_train/weights/best.pt') \n#/kaggle/input/construction-site-safety-image-dataset-roboflow/results_yolov8n_100e/kaggle/working/runs/detect/train/weights/last.pt\n#model= YOLO('/kaggle/working/runs/detect/yolov8n_v1_train2/weights/last.pt')\n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:19:40.195195Z","iopub.execute_input":"2024-02-18T03:19:40.196013Z","iopub.status.idle":"2024-02-18T03:19:40.252084Z","shell.execute_reply.started":"2024-02-18T03:19:40.195973Z","shell.execute_reply":"2024-02-18T03:19:40.251223Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"num_classes = 10\nclasses = [' Hardhat', ' Mask', ' NO-Hardhat', ' NO-Mask', ' NO-Safety Vest', ' Person', ' Safety Cone', ' Safety Vest', ' machinery', ' vehicle']","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:19:37.959935Z","iopub.execute_input":"2024-02-18T03:19:37.961092Z","iopub.status.idle":"2024-02-18T03:19:37.966227Z","shell.execute_reply.started":"2024-02-18T03:19:37.961016Z","shell.execute_reply":"2024-02-18T03:19:37.965116Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"submission=pd.read_csv(\"/kaggle/input/godsensi/SampleSubmission.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:19:56.070771Z","iopub.execute_input":"2024-02-18T03:19:56.071188Z","iopub.status.idle":"2024-02-18T03:19:56.084841Z","shell.execute_reply.started":"2024-02-18T03:19:56.071150Z","shell.execute_reply":"2024-02-18T03:19:56.083674Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"test_csv=pd.read_csv(\"/kaggle/input/godsensi/Test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:19:58.298999Z","iopub.execute_input":"2024-02-18T03:19:58.299945Z","iopub.status.idle":"2024-02-18T03:19:58.312916Z","shell.execute_reply.started":"2024-02-18T03:19:58.299902Z","shell.execute_reply":"2024-02-18T03:19:58.311956Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"submission['filename']=test_csv['filename']","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:20:01.269222Z","iopub.execute_input":"2024-02-18T03:20:01.270247Z","iopub.status.idle":"2024-02-18T03:20:01.276322Z","shell.execute_reply.started":"2024-02-18T03:20:01.270200Z","shell.execute_reply":"2024-02-18T03:20:01.275216Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"probability","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:31:40.949190Z","iopub.execute_input":"2024-02-18T03:31:40.949598Z","iopub.status.idle":"2024-02-18T03:31:40.956304Z","shell.execute_reply.started":"2024-02-18T03:31:40.949562Z","shell.execute_reply":"2024-02-18T03:31:40.955159Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"0.0"},"metadata":{}}]},{"cell_type":"code","source":"submission.to_csv(\"mm.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:30:45.304090Z","iopub.execute_input":"2024-02-18T03:30:45.304582Z","iopub.status.idle":"2024-02-18T03:30:45.313520Z","shell.execute_reply.started":"2024-02-18T03:30:45.304541Z","shell.execute_reply":"2024-02-18T03:30:45.312430Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import torch\n\nfor index, row in submission.iterrows():\n    results = model.predict(source=os.path.join(INPUT_DIR, 'test', row['filename']), save=True)\n    classes = ['Hardhat', 'Mask', 'NO-Hardhat', 'NO-Mask', 'NO-Safety Vest', 'Person', 'Safety Cone', 'Safety Vest', 'machinery', 'vehicle']\n    class_probabilities = {class_name: 0.0 for class_name in classes}\n    print(class_probabilities)\n    for result in results:\n        if result.boxes:\n            for box in result.boxes:\n                class_id = int(box.cls)\n                class_name = model.names[class_id]\n                class_probabilities[class_name] = max(class_probabilities[class_name], box.conf)\n    print('Waywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa')\n    print(class_probabilities)\n    \n    for class_name, probability in class_probabilities.items():\n        submission.loc[index, \" \"+class_name] = probability.item() if isinstance(probability, torch.Tensor) else probability\n\nsubmission.fillna(0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:20:08.660243Z","iopub.execute_input":"2024-02-18T03:20:08.661300Z","iopub.status.idle":"2024-02-18T03:20:18.706765Z","shell.execute_reply.started":"2024-02-18T03:20:08.661248Z","shell.execute_reply":"2024-02-18T03:20:18.705734Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"\nimage 1/1 /kaggle/input/godsensi/data/test/006463_jpg.rf.02f19082420ecc5537b9d59abbe6050c.jpg: 640x640 9 Hardhats, 6 NO-Masks, 8 NO-Safety Vests, 11 Persons, 1 Safety Vest, 8.0ms\nSpeed: 1.5ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-34_jpg.rf.03eacc444bae3c5caa3fef5c736c3e40.jpg: 640x640 2 Persons, 1 machinery, 1 vehicle, 8.8ms\nSpeed: 1.5ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/IMG_0871_mp4-23_jpg.rf.03f872b1ed87ad7fadc85e09475ad37a.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 8.1ms\nSpeed: 1.4ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-596_jpg.rf.11a8a4ac01d8aadb80eeb0406dfa579a.jpg: 640x640 1 NO-Safety Vest, 1 Person, 9.1ms\nSpeed: 1.3ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/ka_01181_png_jpg.rf.154ee4ef254eabd62e316be50470c578.jpg: 640x640 1 Person, 8 Safety Cones, 1 vehicle, 8.4ms\nSpeed: 1.3ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9234], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.8040], device='cuda:0'), 'NO-Safety Vest': tensor([0.9104], device='cuda:0'), 'Person': tensor([0.9134], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.4170], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.3274], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.6390], device='cuda:0'), 'vehicle': tensor([0.8620], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.8964], device='cuda:0'), 'NO-Hardhat': tensor([0.7091], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.7966], device='cuda:0'), 'Person': tensor([0.9180], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.3170], device='cuda:0'), 'Person': tensor([0.9408], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"\nimage 1/1 /kaggle/input/godsensi/data/test/2008_008519_jpg.rf.1798c8eed7de04399a0e7e297b4b4c9e.jpg: 640x640 2 Hardhats, 2 NO-Safety Vests, 6 Persons, 2 Safety Vests, 1 machinery, 8.3ms\nSpeed: 1.3ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-388_jpg.rf.18caa1da4f818a65f73e48463cb2270e.jpg: 640x640 3 machinerys, 8.7ms\nSpeed: 1.3ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/004063_jpg.rf.1b7cdc4035bcb24ef69b8798b444053e.jpg: 640x640 5 Hardhats, 5 NO-Safety Vests, 6 Persons, 1 Safety Vest, 8.2ms\nSpeed: 1.3ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-186_jpg.rf.1f1d93447d4be3233c22c4ce9f6e0601.jpg: 640x640 1 Hardhat, 1 Person, 1 Safety Vest, 1 machinery, 8.3ms\nSpeed: 1.3ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"Waywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.4081], device='cuda:0'), 'Safety Cone': tensor([0.7346], device='cuda:0'), 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': tensor([0.9523], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.3929], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.7693], device='cuda:0'), 'Person': tensor([0.7171], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.6725], device='cuda:0'), 'machinery': tensor([0.5572], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.8669], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9679], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.9367], device='cuda:0'), 'Person': tensor([0.9067], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.7988], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.8212], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.8177], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.9130], device='cuda:0'), 'machinery': tensor([0.4433], device='cuda:0'), 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/image_55_jpg.rf.27ae4341a9b9647d73a8929ff7a22369.jpg: 640x640 1 Hardhat, 1 Mask, 1 Person, 1 Safety Vest, 8.6ms\nSpeed: 1.4ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/IMG_5846_jpg.rf.0b9984069116e2acd928568eb7a8e214.jpg: 640x640 21 Hardhats, 30 NO-Masks, 38 Persons, 24 Safety Vests, 9.2ms\nSpeed: 1.4ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/bookstore_44_08_flickr_jpg.rf.244b6f308c529933af798c4063e58601.jpg: 640x640 (no detections), 8.7ms\nSpeed: 1.4ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/0_jpg.rf.2ff49f74309118f169e07aa12564df87.jpg: 640x640 1 Hardhat, 8 Persons, 1 Safety Vest, 1 machinery, 1 vehicle, 8.4ms\nSpeed: 1.5ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9032], device='cuda:0'), 'Mask': tensor([0.8045], device='cuda:0'), 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.8290], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.9641], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9119], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.6861], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.9315], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.9351], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.3198], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.7936], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.7242], device='cuda:0'), 'machinery': tensor([0.6210], device='cuda:0'), 'vehicle': tensor([0.4925], device='cuda:0')}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/youtube-471_jpg.rf.4296b7bd9a5a07753077beddbcd651bf.jpg: 640x640 1 Person, 1 Safety Vest, 9.5ms\nSpeed: 1.5ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/IMG_3100_mp4-9_jpg.rf.413ccf5fe4a7ee67f71e07c2c43b6756.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 12.9ms\nSpeed: 1.8ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/thumbnail-ba5c72edb320b49a69e86b05775c49b2-scaled-1_jpeg_jpg.rf.3bb460e284098219861b894fb0db13d5.jpg: 640x640 7 Masks, 9 NO-Hardhats, 11 NO-Safety Vests, 13 Persons, 13.3ms\nSpeed: 1.7ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-263_jpg.rf.374e343e12ead395440dbd81417e1be9.jpg: 640x640 2 Persons, 1 Safety Vest, 2 machinerys, 15 vehicles, 9.4ms\nSpeed: 1.5ms preprocess, 9.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.8184], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.9010], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.8935], device='cuda:0'), 'NO-Hardhat': tensor([0.6074], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.5754], device='cuda:0'), 'Person': tensor([0.8921], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.9602], device='cuda:0'), 'NO-Hardhat': tensor([0.9116], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.7946], device='cuda:0'), 'Person': tensor([0.9003], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.7202], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.7111], device='cuda:0'), 'machinery': tensor([0.7802], device='cuda:0'), 'vehicle': tensor([0.9271], device='cuda:0')}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/Inside-merge_mov-58_jpg.rf.50147e19cb655e74c2df0047113e82b2.jpg: 640x640 (no detections), 9.2ms\nSpeed: 1.5ms preprocess, 9.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/IMG_0871_mp4-11_jpg.rf.432092b53ebeb84f4b9b27b40343c9aa.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 9.9ms\nSpeed: 1.7ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/autox_mp4-44_jpg.rf.5048603ee6ccedf9ae6e3f787b7f82ff.jpg: 640x640 20 Safety Cones, 1 vehicle, 9.1ms\nSpeed: 1.5ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/IMG_0871_MOV-12_jpg.rf.36858a9d51613f9a39b7855b54dfa098.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 9.1ms\nSpeed: 1.6ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/image_53_jpg.rf.3446e366b5d4d905a32e1aedc8fe87de.jpg: 640x640 1 Hardhat, 1 Mask, 1 Person, 1 Safety Vest, 8.9ms\nSpeed: 1.5ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.9121], device='cuda:0'), 'NO-Hardhat': tensor([0.6027], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.6561], device='cuda:0'), 'Person': tensor([0.9329], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': tensor([0.8737], device='cuda:0'), 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': tensor([0.9014], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.8794], device='cuda:0'), 'NO-Hardhat': tensor([0.7130], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.6653], device='cuda:0'), 'Person': tensor([0.9359], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n","output_type":"stream"},{"name":"stderr","text":"\nimage 1/1 /kaggle/input/godsensi/data/test/librairie_51_jpg.rf.56b0500ae2ad3820b4286133b627e59c.jpg: 640x640 (no detections), 13.9ms\nSpeed: 1.8ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/2009_000059_jpg.rf.50e8398a37eb33f33fd9f662feeea083.jpg: 640x640 1 NO-Hardhat, 2 NO-Masks, 1 NO-Safety Vest, 2 Persons, 8.9ms\nSpeed: 1.5ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/004763_jpg.rf.46484e6ca73caeaa9de45822cf1085a9.jpg: 640x640 3 Hardhats, 3 NO-Masks, 3 NO-Safety Vests, 3 Persons, 9.1ms\nSpeed: 1.4ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': tensor([0.9449], device='cuda:0'), 'Mask': tensor([0.9029], device='cuda:0'), 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.8195], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.9548], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': tensor([0.7045], device='cuda:0'), 'NO-Mask': tensor([0.6187], device='cuda:0'), 'NO-Safety Vest': tensor([0.9062], device='cuda:0'), 'Person': tensor([0.7904], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9362], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.8877], device='cuda:0'), 'NO-Safety Vest': tensor([0.8336], device='cuda:0'), 'Person': tensor([0.8495], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/construction-192-_jpg.rf.56dd5c4c1396c6ad01be4fbec3bca46f.jpg: 640x640 1 Person, 2 machinerys, 8.4ms\nSpeed: 1.3ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/IMG_3100_mp4-12_jpg.rf.58849ca6a931c2cfe1b17fb4206d9d82.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 8.3ms\nSpeed: 1.5ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-510_jpg.rf.62f82e36d134d53587edb48f291986f4.jpg: 640x640 (no detections), 7.8ms\nSpeed: 1.4ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-253_jpg.rf.5ad0a2d701e20141940508b809584856.jpg: 640x640 (no detections), 8.3ms\nSpeed: 1.3ms preprocess, 8.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-114_jpg.rf.5e02b6574ace1f4b3689befbc5051cd0.jpg: 640x640 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 8.9ms\nSpeed: 1.4ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.3825], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.8763], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.8766], device='cuda:0'), 'NO-Hardhat': tensor([0.7460], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.5315], device='cuda:0'), 'Person': tensor([0.8853], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.2999], device='cuda:0'), 'NO-Safety Vest': tensor([0.5499], device='cuda:0'), 'Person': tensor([0.8740], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/ppe_1073_jpg.rf.72ea8a293a4f3e1135219e33701b1099.jpg: 640x640 10 Hardhats, 6 NO-Masks, 13 Persons, 9 Safety Vests, 9.2ms\nSpeed: 1.5ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/Bookstore_More_Merchandise_jpg.rf.7ab5add3e28ced74f9b316e794cc04d2.jpg: 640x640 (no detections), 11.3ms\nSpeed: 1.8ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-671_jpg.rf.7b08643d6754cabe6caf2b49a963de47.jpg: 640x640 (no detections), 13.8ms\nSpeed: 1.7ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-651-_jpg.rf.8fa283ce7693dbdf29eb98384f24cb85.jpg: 640x640 2 machinerys, 9.1ms\nSpeed: 1.5ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9342], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.5519], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.8981], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.8943], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.8313], device='cuda:0'), 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/autox3_mp4-187_jpg.rf.8340e2bd65afade3fb0d3194eadc5796.jpg: 640x640 5 Safety Cones, 1 vehicle, 11.3ms\nSpeed: 1.4ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-639-_jpg.rf.7db2168ad99f643f7e3070733387e3bb.jpg: 640x640 1 machinery, 8.6ms\nSpeed: 1.3ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-152_jpg.rf.9147878e3ddda845e58f7d9c041f1338.jpg: 640x640 5 Persons, 5 machinerys, 14 vehicles, 9.1ms\nSpeed: 1.4ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-126_jpg.rf.786824e90daf3276130ca73ca610a8da.jpg: 640x640 2 NO-Hardhats, 1 NO-Mask, 2 NO-Safety Vests, 2 Persons, 3 machinerys, 9.4ms\nSpeed: 1.4ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/-4405-_png_jpg.rf.82b5c10b2acd1cfaa24259ada8e599fe.jpg: 640x640 1 Person, 9.0ms\nSpeed: 1.4ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': tensor([0.8916], device='cuda:0'), 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': tensor([0.8160], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.6271], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.6086], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.9156], device='cuda:0'), 'vehicle': tensor([0.6844], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': tensor([0.7836], device='cuda:0'), 'NO-Mask': tensor([0.4113], device='cuda:0'), 'NO-Safety Vest': tensor([0.9047], device='cuda:0'), 'Person': tensor([0.8835], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.7200], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"\nimage 1/1 /kaggle/input/godsensi/data/test/006672_jpg.rf.87d5978c486feb53177408cf00a0d87f.jpg: 640x640 6 Hardhats, 2 NO-Masks, 7 Persons, 7 Safety Vests, 8.8ms\nSpeed: 1.5ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/000005_jpg.rf.96e9379ccae638140c4a90fc4b700a2b.jpg: 640x640 2 Hardhats, 2 NO-Masks, 2 Persons, 9.1ms\nSpeed: 1.4ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-631_jpg.rf.7c6ecf859c1b0a659f8ea057ad27aebd.jpg: 640x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 12.2ms\nSpeed: 1.6ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"Waywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.7937], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9166], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.7449], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.8950], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.9184], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9459], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.8260], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.8087], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.8983], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.8823], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.8789], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.8815], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/003357_jpg.rf.9867f91e88089bb68dc95947d5116d14.jpg: 640x640 1 Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 1 Safety Cone, 8.9ms\nSpeed: 1.4ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/Image36_jpg.rf.8704f3450f736cdd01a61dcee588f2c2.jpg: 640x640 11 Hardhats, 1 NO-Hardhat, 5 NO-Masks, 7 NO-Safety Vests, 15 Persons, 8.6ms\nSpeed: 1.3ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/2009_000496_jpg.rf.9a2d210fe0f5ea4b572aeb07e41ecbae.jpg: 640x640 5 Persons, 8.6ms\nSpeed: 1.4ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/class2_131_jpg.rf.ad8314a9273471f1280ce8789ea75376.jpg: 640x640 1 NO-Safety Vest, 1 Person, 8.6ms\nSpeed: 1.3ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.5842], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.4276], device='cuda:0'), 'NO-Safety Vest': tensor([0.4793], device='cuda:0'), 'Person': tensor([0.6488], device='cuda:0'), 'Safety Cone': tensor([0.6373], device='cuda:0'), 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9210], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': tensor([0.3260], device='cuda:0'), 'NO-Mask': tensor([0.8211], device='cuda:0'), 'NO-Safety Vest': tensor([0.8669], device='cuda:0'), 'Person': tensor([0.9218], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.6400], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.4378], device='cuda:0'), 'Person': tensor([0.8484], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/777_jpg.rf.92dc6945342410ced7ac93f3dfbff0c5.jpg: 640x640 1 Safety Cone, 8.7ms\nSpeed: 1.2ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-108_jpg.rf.9dc7ed5f816f07d520f3dbfaad08d40f.jpg: 640x640 2 Hardhats, 3 NO-Masks, 2 Persons, 2 Safety Vests, 9.7ms\nSpeed: 1.7ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-800-_jpg.rf.a01fcddd0db9cc89c0cacf4af88c468d.jpg: 640x640 2 machinerys, 8.8ms\nSpeed: 1.3ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-840_jpg.rf.974a83a7c5aee7c16e83435b043c6d96.jpg: 640x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1 machinery, 2 vehicles, 8.4ms\nSpeed: 1.4ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-192_jpg.rf.93bea040de8cd55f34ffb12f6ffe30b1.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Mask, 2 NO-Safety Vests, 1 Person, 1 Safety Vest, 12.4ms\nSpeed: 1.7ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': tensor([0.8755], device='cuda:0'), 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.8935], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.6659], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.8253], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.9036], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.5384], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9095], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.6005], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.9106], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.8842], device='cuda:0'), 'machinery': tensor([0.5477], device='cuda:0'), 'vehicle': tensor([0.9295], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"\nimage 1/1 /kaggle/input/godsensi/data/test/Movie-on-10-31-22-at-10_08-AM_mov-20_jpg.rf.aea4278b41550cdb75df5891a26052e7.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 9.1ms\nSpeed: 2.1ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-738_jpg.rf.6f300b76e12b325f7c373c95ef319005.jpg: 640x640 1 Hardhat, 1 NO-Mask, 1 Person, 2 Safety Vests, 8.6ms\nSpeed: 1.4ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-1159-_jpg.rf.9f3172102a34edb157b556a73931c831.jpg: 640x640 1 machinery, 8.8ms\nSpeed: 1.5ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/class1_150_jpg.rf.5995dce34d38deb9eb0b6e36cae78f17.jpg: 640x640 1 Hardhat, 1 NO-Hardhat, 2 NO-Safety Vests, 2 Persons, 9.0ms\nSpeed: 1.5ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Waywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.3138], device='cuda:0'), 'NO-Hardhat': tensor([0.8463], device='cuda:0'), 'NO-Mask': tensor([0.8766], device='cuda:0'), 'NO-Safety Vest': tensor([0.7556], device='cuda:0'), 'Person': tensor([0.8753], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.3111], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.9220], device='cuda:0'), 'NO-Hardhat': tensor([0.8719], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.9158], device='cuda:0'), 'Person': tensor([0.8509], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9113], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.4692], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.8721], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.4973], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.8313], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.7980], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': tensor([0.6125], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.8862], device='cuda:0'), 'Person': tensor([0.8432], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"\nimage 1/1 /kaggle/input/godsensi/data/test/RPReplay_Final1667001201_MP4-100_jpg.rf.9a1b50c4301c53b3ae534c6353337df9.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 10.0ms\nSpeed: 2.1ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-263_jpg.rf.bb17b89dd2ec9a090ce53b728f48865e.jpg: 640x640 1 Hardhat, 1 NO-Safety Vest, 1 Person, 11.3ms\nSpeed: 2.2ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/class2_145_jpg.rf.b8ed5a5357ee41f8fb1aa9b01a400d51.jpg: 640x640 2 NO-Hardhats, 2 NO-Masks, 2 NO-Safety Vests, 2 Persons, 1 machinery, 11.0ms\nSpeed: 1.7ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/3e7e40981ddd4cdb055c7ffe4c2af5d8_jpg.rf.bac50dc18195e9aeb6f3a21782a3efcb.jpg: 640x640 (no detections), 12.9ms\nSpeed: 1.7ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.9124], device='cuda:0'), 'NO-Hardhat': tensor([0.7688], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.6506], device='cuda:0'), 'Person': tensor([0.9410], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.8751], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.7664], device='cuda:0'), 'Person': tensor([0.8697], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': tensor([0.9087], device='cuda:0'), 'NO-Mask': tensor([0.2792], device='cuda:0'), 'NO-Safety Vest': tensor([0.8470], device='cuda:0'), 'Person': tensor([0.9381], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.2992], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/IMG_3103_mp4-9_jpg.rf.b31bd2d816465a27aa1eb072f90bb5aa.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 9.7ms\nSpeed: 1.4ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/Movie-on-10-31-22-at-10_08-AM_mov-24_jpg.rf.c50014f3510a484e5bd565460fd0fd5c.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 8.5ms\nSpeed: 1.4ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-213_jpg.rf.da70b1d8cefd3cc9d56e43bb88dfb67d.jpg: 640x640 1 Hardhat, 2 Persons, 1 Safety Vest, 1 machinery, 9.4ms\nSpeed: 1.3ms preprocess, 9.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-675-_jpg.rf.bb4a05441be707256175e04929da3478.jpg: 640x640 1 Person, 2 machinerys, 10.9ms\nSpeed: 1.6ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.9024], device='cuda:0'), 'NO-Hardhat': tensor([0.8539], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.2789], device='cuda:0'), 'Person': tensor([0.9278], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.9099], device='cuda:0'), 'NO-Hardhat': tensor([0.4137], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.8821], device='cuda:0'), 'Person': tensor([0.5066], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.6693], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.7761], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.8215], device='cuda:0'), 'machinery': tensor([0.7973], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.2602], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.8972], device='cuda:0'), 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/youtube-53_jpg.rf.e96f8f81389f4e63a79663095680a617.jpg: 640x640 1 NO-Safety Vest, 2 Persons, 2 vehicles, 14.1ms\nSpeed: 1.7ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-496_jpg.rf.def4e9964e9a354d0a02f4ac14334a73.jpg: 640x640 (no detections), 14.0ms\nSpeed: 1.8ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-462_jpg.rf.df73aa5089a04b8fbf3adf9d614a6740.jpg: 640x640 2 Hardhats, 2 Persons, 2 Safety Vests, 2 vehicles, 9.0ms\nSpeed: 1.4ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-597-_jpg.rf.e18e918aae0aeecfdf8348513636d344.jpg: 640x640 2 machinerys, 8.3ms\nSpeed: 1.3ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/2008_008320_jpg.rf.bd34011d46f82f9410d95f00e560b8ea.jpg: 640x640 1 NO-Hardhat, 4 Persons, 1 Safety Vest, 8.7ms\nSpeed: 1.4ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.5029], device='cuda:0'), 'Person': tensor([0.6862], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': tensor([0.5511], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9002], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.7815], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.8164], device='cuda:0'), 'machinery': 0.0, 'vehicle': tensor([0.8855], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.9025], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': tensor([0.8236], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.8246], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.9010], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-472_jpg.rf.e9425ff40c0df2beeef70abbc2324956.jpg: 640x640 1 Person, 1 Safety Vest, 8.2ms\nSpeed: 1.6ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/002551_jpg.rf.ce4b9f934161faa72c80dc6898d37b2d.jpg: 640x640 2 Hardhats, 1 NO-Mask, 4 NO-Safety Vests, 3 Persons, 8.9ms\nSpeed: 1.5ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/autox3_mp4-65_jpg.rf.d933ce48947fa9bdb55dc702a0879ac9.jpg: 640x640 3 Safety Cones, 1 vehicle, 8.5ms\nSpeed: 1.5ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/ppe_0018_jpg.rf.be66fabcc8627f60d963454b5a227095.jpg: 640x640 2 Hardhats, 2 NO-Masks, 2 NO-Safety Vests, 2 Persons, 8.8ms\nSpeed: 1.4ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.7295], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.9322], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9003], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.3821], device='cuda:0'), 'NO-Safety Vest': tensor([0.8072], device='cuda:0'), 'Person': tensor([0.8842], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': tensor([0.9317], device='cuda:0'), 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': tensor([0.8399], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9544], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.7719], device='cuda:0'), 'NO-Safety Vest': tensor([0.7789], device='cuda:0'), 'Person': tensor([0.8646], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/autox3_mp4-277_jpg.rf.a5ed8fd043fe7e1d8682768880b6d4db.jpg: 640x640 26 Safety Cones, 1 vehicle, 8.8ms\nSpeed: 1.4ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-2-_mp4-162_jpg.rf.efad5f15524c736fe03b9c9936adc481.jpg: 640x640 2 machinerys, 9.1ms\nSpeed: 1.6ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-275-_jpg.rf.e1c57987f9dc262aad1d7c67b694fd87.jpg: 640x640 1 machinery, 9.1ms\nSpeed: 1.4ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-843-_jpg.rf.c0ca85a10f6ad3c1375b37e52a51eeed.jpg: 640x640 4 machinerys, 8.9ms\nSpeed: 1.4ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-237_jpg.rf.d07a927721fe259757237c3706ea22e5.jpg: 640x640 2 Hardhats, 2 NO-Safety Vests, 2 Persons, 2 machinerys, 4 vehicles, 9.2ms\nSpeed: 1.5ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': tensor([0.9059], device='cuda:0'), 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': tensor([0.9016], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.8570], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.7994], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.9270], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.4801], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.5314], device='cuda:0'), 'Person': tensor([0.7865], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.7592], device='cuda:0'), 'vehicle': tensor([0.7867], device='cuda:0')}\n","output_type":"stream"},{"name":"stderr","text":"\nimage 1/1 /kaggle/input/godsensi/data/test/construction-2-_mp4-13_jpg.rf.cef0975976346515d438e0c2ce6c59db.jpg: 640x640 4 machinerys, 8.9ms\nSpeed: 1.5ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/NX_img_177_jpg.rf.c03709e5fadfe2109411f05a9e9bc25f.jpg: 640x640 1 Hardhat, 1 Mask, 3 NO-Hardhats, 2 NO-Safety Vests, 3 Persons, 31.9ms\nSpeed: 2.4ms preprocess, 31.9ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-198_jpg.rf.e89faeb9765c6bd6cece5434d140f4af.jpg: 640x640 1 Person, 1 Safety Vest, 1 machinery, 8.9ms\nSpeed: 1.5ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.9305], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.8811], device='cuda:0'), 'Mask': tensor([0.3294], device='cuda:0'), 'NO-Hardhat': tensor([0.8873], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.8919], device='cuda:0'), 'Person': tensor([0.8922], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.5806], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.8457], device='cuda:0'), 'machinery': tensor([0.7182], device='cuda:0'), 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/construction-2-_mp4-84_jpg.rf.e8d6bb0acc5c6e82c1a2d260ddf3135e.jpg: 640x640 2 machinerys, 9.5ms\nSpeed: 1.6ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/maksssksksss17_png_jpg.rf.f685b497756b1facbf3d4c2d2d22c0d2.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 9.1ms\nSpeed: 1.5ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-51_jpg.rf.083f4487f9a468d9ff42aa13953f377a.jpg: 640x640 (no detections), 9.1ms\nSpeed: 1.5ms preprocess, 9.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/-1079-_png_jpg.rf.19092a3937930012f9fd9c1ce57f5a7b.jpg: 640x640 1 Hardhat, 2 NO-Safety Vests, 4 Persons, 8.5ms\nSpeed: 1.5ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/img_08_jpg.rf.0f132a9c7ca6d12a8a9d1c4b3dbd54da.jpg: 640x640 1 NO-Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 8.6ms\nSpeed: 1.4ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.8432], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.8972], device='cuda:0'), 'NO-Hardhat': tensor([0.6929], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.3850], device='cuda:0'), 'Person': tensor([0.8968], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.5532], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.8018], device='cuda:0'), 'Person': tensor([0.8525], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': tensor([0.7728], device='cuda:0'), 'NO-Mask': tensor([0.8721], device='cuda:0'), 'NO-Safety Vest': tensor([0.7491], device='cuda:0'), 'Person': tensor([0.8248], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/youtube-277_jpg.rf.1bda1581c28b4f6cccd5eda6b23b94ee.jpg: 640x640 3 Hardhats, 2 NO-Safety Vests, 2 Persons, 15.9ms\nSpeed: 1.7ms preprocess, 15.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/Mask2_mov-15_jpg.rf.026bd9a95154b1ead451a722a25ed130.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 9.0ms\nSpeed: 1.5ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/ppe_0665_jpg.rf.1dad479f7f54b2a7127cf18ef74ffd85.jpg: 640x640 3 Hardhats, 1 Mask, 4 NO-Hardhats, 6 NO-Masks, 5 NO-Safety Vests, 8 Persons, 3 Safety Vests, 1 vehicle, 8.9ms\nSpeed: 1.4ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-2-_mp4-38_jpg.rf.0bb63aba0a9ebe5a4741a6207e2e1902.jpg: 640x640 1 Person, 2 machinerys, 8.9ms\nSpeed: 1.4ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.7542], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.8623], device='cuda:0'), 'Person': tensor([0.9367], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.7998], device='cuda:0'), 'NO-Hardhat': tensor([0.7242], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.6859], device='cuda:0'), 'Person': tensor([0.9185], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9367], device='cuda:0'), 'Mask': tensor([0.3643], device='cuda:0'), 'NO-Hardhat': tensor([0.8889], device='cuda:0'), 'NO-Mask': tensor([0.8466], device='cuda:0'), 'NO-Safety Vest': tensor([0.9527], device='cuda:0'), 'Person': tensor([0.8752], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.9587], device='cuda:0'), 'machinery': 0.0, 'vehicle': tensor([0.7604], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.2602], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.9241], device='cuda:0'), 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/youtube-200_jpg.rf.2c8aaf9fb58df4a3af442c293217d0c5.jpg: 640x640 1 Hardhat, 1 NO-Safety Vest, 1 Person, 1 Safety Vest, 12.0ms\nSpeed: 1.5ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-504_jpg.rf.23771986686856ac7d350cea84ddf611.jpg: 640x640 1 Hardhat, 1 NO-Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 1 Safety Vest, 2 vehicles, 12.7ms\nSpeed: 1.6ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-391_jpg.rf.2744ad86e8dbd4366f1fa839accc48b3.jpg: 640x640 1 Hardhat, 1 Person, 2 Safety Vests, 8.8ms\nSpeed: 1.3ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-274-_jpg.rf.21181010ffb2b9ea429080ccd258e3ae.jpg: 640x640 2 machinerys, 9.0ms\nSpeed: 1.5ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/residential_jpg.rf.17181770c64333009b9101e1572c5112.jpg: 640x640 1 NO-Hardhat, 2 NO-Safety Vests, 2 Persons, 8.8ms\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.6190], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.4705], device='cuda:0'), 'Person': tensor([0.7273], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.7390], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.5731], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': tensor([0.2789], device='cuda:0'), 'NO-Mask': tensor([0.3617], device='cuda:0'), 'NO-Safety Vest': tensor([0.4671], device='cuda:0'), 'Person': tensor([0.8783], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.8529], device='cuda:0'), 'machinery': 0.0, 'vehicle': tensor([0.8666], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.7839], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.6718], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.7871], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.8869], device='cuda:0'), 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"Speed: 1.4ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-617_jpg.rf.309ef116f1d9074886d61bb0816b6b9e.jpg: 640x640 2 Hardhats, 1 NO-Mask, 2 Persons, 2 Safety Vests, 9.0ms\nSpeed: 1.4ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/ppe_1228_jpg.rf.29b714c415ea74df3160f56a603463a0.jpg: 640x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 8.5ms\nSpeed: 1.4ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-70_jpg.rf.2d5f69c78f062dfc572ccb6ce6bc3c9b.jpg: 640x640 1 Person, 4 machinerys, 8.6ms\nSpeed: 1.4ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/1125_jpg.rf.2958d0a57630bdde8c3b5c6c560152af.jpg: 640x640 2 NO-Safety Vests, 4 Persons, 1 Safety Cone, 8.1ms\nSpeed: 1.3ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': tensor([0.4938], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.8349], device='cuda:0'), 'Person': tensor([0.9269], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9247], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.6115], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.8385], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.8750], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9457], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.8912], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.6473], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.6951], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.3290], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.9096], device='cuda:0'), 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-584_jpg.rf.3136186a0786384c1ffc261f4d40ea42.jpg: 640x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 8.8ms\nSpeed: 1.3ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/IMG_3103_mp4-17_jpg.rf.3223d405c1b3657aa54e170e32c8fe52.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 8.4ms\nSpeed: 1.3ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/644_jpg.rf.39197521b9addbcfa9d3620d85004e2d.jpg: 640x640 1 NO-Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 2 Persons, 1 Safety Cone, 8.9ms\nSpeed: 1.3ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/Movie-on-10-31-22-at-10_08-AM_mov-6_jpg.rf.344372295a53aaf103587c9714ec98f7.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 8.8ms\nSpeed: 1.3ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.8931], device='cuda:0'), 'Person': tensor([0.7569], device='cuda:0'), 'Safety Cone': tensor([0.9012], device='cuda:0'), 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9702], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.2682], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.9060], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.8657], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.9134], device='cuda:0'), 'NO-Hardhat': tensor([0.7485], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.7358], device='cuda:0'), 'Person': tensor([0.8630], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': tensor([0.8783], device='cuda:0'), 'NO-Mask': tensor([0.8097], device='cuda:0'), 'NO-Safety Vest': tensor([0.9361], device='cuda:0'), 'Person': tensor([0.8450], device='cuda:0'), 'Safety Cone': tensor([0.9491], device='cuda:0'), 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.9248], device='cuda:0'), 'NO-Hardhat': tensor([0.9157], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.9375], device='cuda:0'), 'Person': tensor([0.6341], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-399_jpg.rf.3472ef7c01bb9092da48f0d562581121.jpg: 640x640 1 Person, 4 machinerys, 1 vehicle, 9.1ms\nSpeed: 1.3ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/02646_jpg.rf.5c93ba95bdc03808bcf872c7218ac5ef.jpg: 640x640 1 Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 8.5ms\nSpeed: 1.4ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/IMG_3103_mp4-18_jpg.rf.39e564f01ba6048fc34853e99f3de11b.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 13.3ms\nSpeed: 1.8ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-476_jpg.rf.3744f21a7b74ea642bbcbc8251659001.jpg: 640x640 (no detections), 8.3ms\nSpeed: 1.4ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/casino_0448_jpg.rf.090df4137a5926092c541ee5c6918868.jpg: 640x640 (no detections), 8.3ms\nSpeed: 1.3ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.4106], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.9449], device='cuda:0'), 'vehicle': tensor([0.7818], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.8979], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.9509], device='cuda:0'), 'NO-Safety Vest': tensor([0.7210], device='cuda:0'), 'Person': tensor([0.8315], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.8750], device='cuda:0'), 'NO-Hardhat': tensor([0.7040], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.3095], device='cuda:0'), 'Person': tensor([0.9189], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/-1969-_png_jpg.rf.41dd58ed3ae83df95fb2417c679d581f.jpg: 640x640 1 Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 8.8ms\nSpeed: 1.4ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/MariusConePic31_png_jpg.rf.1fd6fccfeef580e0e0061d78d5a248a4.jpg: 640x640 6 Safety Cones, 8.5ms\nSpeed: 1.5ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-3-_mp4-219_jpg.rf.416dbf917b54d5895e2430fa0d6f1b66.jpg: 640x640 2 machinerys, 8.8ms\nSpeed: 1.4ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/soooo_jpg.rf.5980d39f656b4d62672d2164173455e3.jpg: 640x640 1 Mask, 5 NO-Hardhats, 1 NO-Mask, 2 NO-Safety Vests, 5 Persons, 1 Safety Vest, 9.0ms\nSpeed: 1.5ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/2009_000461_jpg.rf.43a28e2d6f1f9d399c92e18ccc9f0bf1.jpg: 640x640 1 Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 9.5ms\nSpeed: 1.7ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9380], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.5557], device='cuda:0'), 'NO-Safety Vest': tensor([0.4339], device='cuda:0'), 'Person': tensor([0.7738], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': tensor([0.9260], device='cuda:0'), 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.9357], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.5903], device='cuda:0'), 'NO-Hardhat': tensor([0.9032], device='cuda:0'), 'NO-Mask': tensor([0.7460], device='cuda:0'), 'NO-Safety Vest': tensor([0.7890], device='cuda:0'), 'Person': tensor([0.9124], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.7635], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"\nimage 1/1 /kaggle/input/godsensi/data/test/ppe_0355_jpg.rf.508753d5b708536eca53de192b927c61.jpg: 640x640 3 Hardhats, 2 NO-Masks, 4 Persons, 3 Safety Vests, 9.7ms\nSpeed: 1.5ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/972_jpg.rf.4c6fac866e4928f3da7591fd2c26c2ac.jpg: 640x640 1 NO-Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 1 Safety Cone, 8.8ms\nSpeed: 1.4ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/class1_206_jpg.rf.3988ff665e55e1cd9dbcd22c87be73d9.jpg: 640x640 1 Hardhat, 3 NO-Hardhats, 6 NO-Masks, 2 NO-Safety Vests, 2 Persons, 8.6ms\nSpeed: 1.4ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/mms_00684_jpg.rf.47567bbd99db89023296aad0b965ff02.jpg: 640x640 2 Safety Cones, 8.4ms\nSpeed: 1.4ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Waywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.5899], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.6135], device='cuda:0'), 'NO-Safety Vest': tensor([0.7373], device='cuda:0'), 'Person': tensor([0.7507], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.8975], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.6950], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.8791], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.9704], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': tensor([0.9002], device='cuda:0'), 'NO-Mask': tensor([0.5991], device='cuda:0'), 'NO-Safety Vest': tensor([0.9060], device='cuda:0'), 'Person': tensor([0.7938], device='cuda:0'), 'Safety Cone': tensor([0.9352], device='cuda:0'), 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.8233], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': tensor([0.7980], device='cuda:0'), 'NO-Mask': tensor([0.5007], device='cuda:0'), 'NO-Safety Vest': tensor([0.9139], device='cuda:0'), 'Person': tensor([0.9256], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n","output_type":"stream"},{"name":"stderr","text":"\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-455_jpg.rf.35acd2e91608806a26f3ac4e784ea512.jpg: 640x640 2 Hardhats, 2 NO-Masks, 2 Persons, 2 Safety Vests, 1 vehicle, 8.6ms\nSpeed: 1.5ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/autox4_mp4-72_jpg.rf.5e9c1836f027bf40eb8898e68f2efdeb.jpg: 640x640 7 Safety Cones, 1 vehicle, 8.4ms\nSpeed: 1.5ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-487_jpg.rf.5f1c67ece433c16da8ed3c9200ef4b5f.jpg: 640x640 1 Hardhat, 2 Persons, 2 Safety Vests, 8.1ms\nSpeed: 1.3ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-3-_mp4-21_jpg.rf.4fc9ff5afc8387b5c673a424781c527c.jpg: 640x640 1 Person, 3 machinerys, 8.2ms\nSpeed: 1.4ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': tensor([0.9246], device='cuda:0'), 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.8755], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.7408], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.8214], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.8640], device='cuda:0'), 'machinery': 0.0, 'vehicle': tensor([0.5817], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': tensor([0.8306], device='cuda:0'), 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': tensor([0.9086], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.3303], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.6459], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.5128], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.5554], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.8867], device='cuda:0'), 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/005559_jpg.rf.5a5ab91289de227b286efca4418ff73d.jpg: 640x640 1 Hardhat, 1 NO-Safety Vest, 3 Persons, 8.4ms\nSpeed: 1.3ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-470_jpg.rf.6aebf4cfb6c5a7e703c6532ca5090517.jpg: 640x640 1 Person, 1 Safety Vest, 9.1ms\nSpeed: 1.4ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-823-_jpg.rf.640d8abfc7c7689d4a19e6aa00ac8984.jpg: 640x640 1 Person, 1 machinery, 12.3ms\nSpeed: 1.7ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/IMG_3094_mp4-3_jpg.rf.65429c37fcf92b2ba8cfc9d2180051ef.jpg: 640x640 1 NO-Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 10.0ms\nSpeed: 1.5ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-711-_jpg.rf.50a19be8c0ae3cd1a82cd543a9bb6a14.jpg: 640x640 1 machinery, 8.9ms\nSpeed: 1.3ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9551], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.8776], device='cuda:0'), 'Person': tensor([0.8067], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.8511], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.9495], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.7341], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.8478], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': tensor([0.6547], device='cuda:0'), 'NO-Mask': tensor([0.8655], device='cuda:0'), 'NO-Safety Vest': tensor([0.7968], device='cuda:0'), 'Person': tensor([0.9041], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.8735], device='cuda:0'), 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"\nimage 1/1 /kaggle/input/godsensi/data/test/2009_004100_jpg.rf.6eb0dc058fc0d307a6b0f7f579945e24.jpg: 640x640 1 NO-Hardhat, 1 NO-Mask, 2 NO-Safety Vests, 1 Person, 9.2ms\nSpeed: 1.5ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/518_jpg.rf.73999663994434126ac8b7ac5dbe6b52.jpg: 640x640 1 NO-Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 2 Persons, 1 Safety Cone, 8.2ms\nSpeed: 1.4ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-194_jpg.rf.601da70a10e87c30c693ffbee53b17a7.jpg: 640x640 1 Person, 1 Safety Vest, 2 machinerys, 8.5ms\nSpeed: 1.3ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/YouTube_FreeStockFootage_People-wearing-face-mask_Empty-Street_Covid19-D_DbgrvhlGs-720p_mp4-66_jpg.rf.72af13fb1f20520e0d41547037ced88b.jpg: 640x640 1 Hardhat, 4 NO-Safety Vests, 8 Persons, 14.9ms\nSpeed: 1.7ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': tensor([0.6406], device='cuda:0'), 'NO-Mask': tensor([0.8422], device='cuda:0'), 'NO-Safety Vest': tensor([0.4042], device='cuda:0'), 'Person': tensor([0.7971], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': tensor([0.7773], device='cuda:0'), 'NO-Mask': tensor([0.7895], device='cuda:0'), 'NO-Safety Vest': tensor([0.8470], device='cuda:0'), 'Person': tensor([0.8025], device='cuda:0'), 'Safety Cone': tensor([0.9336], device='cuda:0'), 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.5687], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.6982], device='cuda:0'), 'machinery': tensor([0.6540], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.2942], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.5249], device='cuda:0'), 'Person': tensor([0.7719], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/IMG_9949-1-_mp4-20_jpg.rf.6ff2adfaf91058088d86084475d4d575.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 9.2ms\nSpeed: 1.5ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/RPReplay_Final1667001201_MP4-454_jpg.rf.74024a799f518f9a6314ed301827eb1b.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 13.3ms\nSpeed: 1.4ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/-1429-_png_jpg.rf.78a7894e86c79d018d80fa86f4d000f8.jpg: 640x640 3 Hardhats, 1 NO-Mask, 2 NO-Safety Vests, 2 Persons, 14.7ms\nSpeed: 1.7ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-1023-_jpg.rf.7b73352606fb1d79619d34031c07a232.jpg: 640x640 2 machinerys, 11.7ms\nSpeed: 1.5ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.8776], device='cuda:0'), 'NO-Hardhat': tensor([0.7075], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.6213], device='cuda:0'), 'Person': tensor([0.8994], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.8879], device='cuda:0'), 'NO-Hardhat': tensor([0.7955], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.3547], device='cuda:0'), 'Person': tensor([0.8971], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.8500], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.4253], device='cuda:0'), 'NO-Safety Vest': tensor([0.9504], device='cuda:0'), 'Person': tensor([0.8552], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.8803], device='cuda:0'), 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/IMG_5024_mp4-8_jpg.rf.6b626854d6228eab4c341ddd5f8b5e46.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 13.8ms\nSpeed: 1.7ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/airport_inside_0090_jpg.rf.663e21100a3c4bc66a41cceba5403e51.jpg: 640x640 1 NO-Safety Vest, 3 Persons, 8.6ms\nSpeed: 1.4ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/Mask2_mov-11_jpg.rf.34ddcb1a619624541a2cca4400b7cd92.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 12.0ms\nSpeed: 1.7ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-619_jpg.rf.93749f0e33b2f7beb302dd2e176d768a.jpg: 640x640 2 Hardhats, 1 NO-Mask, 2 Persons, 2 Safety Vests, 8.7ms\nSpeed: 1.4ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.8766], device='cuda:0'), 'NO-Hardhat': tensor([0.6517], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.4580], device='cuda:0'), 'Person': tensor([0.8931], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.2569], device='cuda:0'), 'Person': tensor([0.6092], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.8252], device='cuda:0'), 'NO-Hardhat': tensor([0.6513], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.6150], device='cuda:0'), 'Person': tensor([0.9208], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9378], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.6587], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.8363], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.8597], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/airport_inside_0115_jpg.rf.8277ce4e71886a343bfdb10ce7fb6d4a.jpg: 640x640 (no detections), 13.3ms\nSpeed: 1.6ms preprocess, 13.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/class1_077_jpg.rf.84c3583c1866262daeb1618b80e18df9.jpg: 640x640 1 Hardhat, 2 NO-Safety Vests, 3 Persons, 11.1ms\nSpeed: 1.7ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/-3766-_png_jpg.rf.81ead992d4b8047ec7beb28b7532cf0a.jpg: 640x640 13 Hardhats, 4 NO-Hardhats, 3 NO-Masks, 11 NO-Safety Vests, 19 Persons, 8.4ms\nSpeed: 1.4ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/Movie-on-10-31-22-at-10_08-AM_mov-13_jpg.rf.91dc3b79da617fb2e4321f27f48f21f4.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 8.8ms\nSpeed: 1.4ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.8391], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.8753], device='cuda:0'), 'Person': tensor([0.9007], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9733], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': tensor([0.8757], device='cuda:0'), 'NO-Mask': tensor([0.6532], device='cuda:0'), 'NO-Safety Vest': tensor([0.7751], device='cuda:0'), 'Person': tensor([0.8874], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.9213], device='cuda:0'), 'NO-Hardhat': tensor([0.6537], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.9196], device='cuda:0'), 'Person': tensor([0.8947], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/youtube-260_jpg.rf.76ba0c9fa66318daee5bea72b83b4cc5.jpg: 640x640 4 machinerys, 23 vehicles, 8.5ms\nSpeed: 1.3ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-392_jpg.rf.7e49e3a8486caaa4e9d82246de93e68e.jpg: 640x640 1 Person, 1 Safety Vest, 8.7ms\nSpeed: 1.4ms preprocess, 8.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/2009_002778_jpg.rf.7c8977ed190a2ce4211ef58f66864066.jpg: 640x640 1 Person, 8.6ms\nSpeed: 1.3ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-405_jpg.rf.6d1fc463659ac0d8e735bc1e731086a0.jpg: 640x640 1 Person, 8.7ms\nSpeed: 1.4ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/-1989-_png_jpg.rf.8cb3d6087bb86d08e693b4250fbf96e3.jpg: 640x640 4 Hardhats, 4 NO-Masks, 7 NO-Safety Vests, 8 Persons, 8.0ms\nSpeed: 1.3ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.9047], device='cuda:0'), 'vehicle': tensor([0.9052], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.7816], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.8512], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.7556], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.3083], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9093], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.7666], device='cuda:0'), 'NO-Safety Vest': tensor([0.7802], device='cuda:0'), 'Person': tensor([0.8776], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/681_jpg.rf.7a0a7ef78f7dc01872cc3130dc3b354e.jpg: 640x640 3 Safety Cones, 8.2ms\nSpeed: 1.4ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-308_jpg.rf.790ae393e769f8e6280734b7506523ab.jpg: 640x640 1 Hardhat, 1 NO-Safety Vest, 1 Person, 2 vehicles, 8.5ms\nSpeed: 1.4ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/IMG_3100_mp4-1_jpg.rf.7b4a6df995ec2702dee6e7f8c5b47e14.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 8.6ms\nSpeed: 1.4ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-118_jpg.rf.9dc8b46dfbac73d9e4f983964355d7ac.jpg: 640x640 1 Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 8.5ms\nSpeed: 1.3ms preprocess, 8.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/004424_jpg.rf.0470713b945b08839105cde711db62d9.jpg: 640x640 1 Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 8.1ms\nSpeed: 1.2ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': tensor([0.9014], device='cuda:0'), 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9326], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.7267], device='cuda:0'), 'Person': tensor([0.9087], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': tensor([0.7102], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.8728], device='cuda:0'), 'NO-Hardhat': tensor([0.7036], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.3095], device='cuda:0'), 'Person': tensor([0.8914], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.8972], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.5320], device='cuda:0'), 'NO-Safety Vest': tensor([0.9021], device='cuda:0'), 'Person': tensor([0.8063], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.8933], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.8073], device='cuda:0'), 'NO-Safety Vest': tensor([0.7035], device='cuda:0'), 'Person': tensor([0.8174], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/youtube-267_jpg.rf.acd9b5f407f573eaa830029418345ad3.jpg: 640x640 1 Safety Cone, 1 vehicle, 8.3ms\nSpeed: 1.5ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/Movie-on-10-31-22-at-10_08-AM_mov-22_jpg.rf.a02b881bb190fa4a30026a648d13d278.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 2 Persons, 8.9ms\nSpeed: 1.4ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/class1_267_jpg.rf.ab7a08d97aba5b0748e976df6e65700a.jpg: 640x640 1 Hardhat, 1 NO-Hardhat, 2 NO-Masks, 2 NO-Safety Vests, 2 Persons, 8.8ms\nSpeed: 1.3ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/4_jpg.rf.a937c41e1fc4d92e9e1f8c2d9efeb87d.jpg: 640x640 3 Persons, 1 Safety Vest, 1 machinery, 8.3ms\nSpeed: 1.3ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/shakespearebookshop_jpg.rf.9a14dbfdd07d9a0cc916cffef0194245.jpg: 640x640 (no detections), 8.1ms\nSpeed: 1.4ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': tensor([0.3121], device='cuda:0'), 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': tensor([0.4637], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.9228], device='cuda:0'), 'NO-Hardhat': tensor([0.8828], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.9164], device='cuda:0'), 'Person': tensor([0.8162], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.7832], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': tensor([0.8138], device='cuda:0'), 'NO-Mask': tensor([0.4423], device='cuda:0'), 'NO-Safety Vest': tensor([0.9235], device='cuda:0'), 'Person': tensor([0.9074], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.7201], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.5094], device='cuda:0'), 'machinery': tensor([0.8640], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/autox4_mp4-63_jpg.rf.b0fab4fd2c947536a122d6f2e7cca895.jpg: 640x640 1 Person, 8 Safety Cones, 1 vehicle, 8.6ms\nSpeed: 1.3ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-179_jpg.rf.bab3fbda351095d3b9aaba8007e3aa87.jpg: 640x640 1 Hardhat, 2 NO-Masks, 1 Person, 1 Safety Vest, 1 vehicle, 8.3ms\nSpeed: 1.3ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-277-_jpg.rf.bf73a4edc7a1f7d412bc3267cbafcda7.jpg: 640x640 2 machinerys, 2 vehicles, 8.3ms\nSpeed: 1.3ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-446_jpg.rf.b9d9b80538b79252761946ece0bc6317.jpg: 640x640 (no detections), 8.2ms\nSpeed: 1.3ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-9-_jpg.rf.c2af6f04317b1ea7d6e2a84d776788a2.jpg: 640x640 5 machinerys, 8.3ms\nSpeed: 1.3ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.8139], device='cuda:0'), 'Safety Cone': tensor([0.8354], device='cuda:0'), 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': tensor([0.9085], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.8304], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.5844], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.7043], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.7605], device='cuda:0'), 'machinery': 0.0, 'vehicle': tensor([0.8697], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.7464], device='cuda:0'), 'vehicle': tensor([0.3489], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.9572], device='cuda:0'), 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/youtube-697_jpg.rf.950b34f23e196850ec51a4add2eeb840.jpg: 640x640 1 Hardhat, 2 NO-Masks, 1 Person, 1 Safety Vest, 3 machinerys, 8.5ms\nSpeed: 1.6ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/2009_000277_jpg.rf.baccd85360fb8011e7c303066ceac286.jpg: 640x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 8.7ms\nSpeed: 1.5ms preprocess, 8.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-1114-_jpg.rf.69b25d38992eb6da67701a614f0a3f97.jpg: 640x640 1 machinery, 1 vehicle, 8.5ms\nSpeed: 1.3ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-1-_mp4-147_jpg.rf.a9062a80b06ac796f7afb269e5f18c53.jpg: 640x640 (no detections), 8.3ms\nSpeed: 1.3ms preprocess, 8.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/video_CDC-YOUTUBE_mp4-42_jpg.rf.bbc5cf2369c54126f61f0b1f71f77d8d.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 8.6ms\nSpeed: 1.3ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.8731], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.7666], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.8780], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.9135], device='cuda:0'), 'machinery': tensor([0.9070], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': tensor([0.8220], device='cuda:0'), 'NO-Mask': tensor([0.4811], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.9041], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.7753], device='cuda:0'), 'vehicle': tensor([0.2658], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.8799], device='cuda:0'), 'NO-Hardhat': tensor([0.5396], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.4914], device='cuda:0'), 'Person': tensor([0.9737], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/2009_003991_jpg.rf.c4fadb57b5579062cd4db5463ec3ba74.jpg: 640x640 1 NO-Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 2 Persons, 12.1ms\nSpeed: 1.4ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-416_jpg.rf.8b5d7c27337f84a1cd2b3e8b7c6435a7.jpg: 640x640 1 Person, 9.0ms\nSpeed: 1.4ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-287_jpg.rf.c9a7d5b17f75d0c9ed62ad4127141aa2.jpg: 640x640 1 Hardhat, 1 Person, 2 Safety Vests, 8.8ms\nSpeed: 1.4ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-2-_mp4-149_jpg.rf.c6d3939d4743a346de668a0ae05accbc.jpg: 640x640 1 machinery, 8.3ms\nSpeed: 1.4ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/hospital-corridor_jpg.rf.bbac7f39a08bac2b0363ee9682bd86b2.jpg: 640x640 (no detections), 8.7ms\nSpeed: 1.4ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': tensor([0.8911], device='cuda:0'), 'NO-Mask': tensor([0.3662], device='cuda:0'), 'NO-Safety Vest': tensor([0.8644], device='cuda:0'), 'Person': tensor([0.8146], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.8845], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.7210], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.7824], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.6724], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.8876], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/youtube-540_jpg.rf.b229e14d526db6e53965f59e6146cf15.jpg: 640x640 (no detections), 9.6ms\nSpeed: 1.6ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-804_jpg.rf.c4250b3c54e1cca8d58622970882f60a.jpg: 640x640 (no detections), 8.2ms\nSpeed: 1.3ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-255_jpg.rf.c5a9f8ed208cb72e1a700ba52dc2fdfa.jpg: 640x640 1 Hardhat, 1 NO-Safety Vest, 2 Persons, 1 vehicle, 8.3ms\nSpeed: 1.3ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/172_jpg.rf.9385682a04a12b6043a2ea893d1f319a.jpg: 640x640 6 Safety Cones, 8.9ms\nSpeed: 1.2ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/IMG_4921-2_mp4-122_jpg.rf.d27a983b805c273486c09e20f65a5a6b.jpg: 640x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 8.7ms\nSpeed: 1.4ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.6066], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.3117], device='cuda:0'), 'Person': tensor([0.7460], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': tensor([0.4839], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': tensor([0.9462], device='cuda:0'), 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': tensor([0.7885], device='cuda:0'), 'NO-Mask': tensor([0.4202], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.7760], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/youtube-727_jpg.rf.cb4c039b4ffea84835e67e2e3d2edf6e.jpg: 640x640 2 machinerys, 10.6ms\nSpeed: 1.2ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/00596_jpg.rf.d030c5d98b937d080d75db1c1b269a84.jpg: 640x640 1 Hardhat, 2 NO-Hardhats, 1 NO-Mask, 4 NO-Safety Vests, 3 Persons, 8.2ms\nSpeed: 1.3ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-4-_mp4-20_jpg.rf.cb627b855fa08d83357febb83f6ad4bc.jpg: 640x640 2 machinerys, 9.0ms\nSpeed: 1.3ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-342_jpg.rf.d7e55a17800f8d87313d7b6f33256ea9.jpg: 640x640 3 Persons, 1 Safety Vest, 3 machinerys, 3 vehicles, 8.8ms\nSpeed: 1.3ms preprocess, 8.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-226_jpg.rf.dd9d045ca17155289bcebe722e8a86e9.jpg: 640x640 2 machinerys, 8.3ms\nSpeed: 1.3ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.7351], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9438], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': tensor([0.9159], device='cuda:0'), 'NO-Mask': tensor([0.7651], device='cuda:0'), 'NO-Safety Vest': tensor([0.8985], device='cuda:0'), 'Person': tensor([0.9144], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.9430], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.7745], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.8140], device='cuda:0'), 'machinery': tensor([0.9619], device='cuda:0'), 'vehicle': tensor([0.7717], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.8510], device='cuda:0'), 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/IMG_3103_mp4-16_jpg.rf.d31a50c14cb25c823066fe63793f7792.jpg: 640x640 1 Mask, 2 NO-Hardhats, 1 NO-Safety Vest, 1 Person, 8.3ms\nSpeed: 1.4ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-196-_jpg.rf.f593da25134315b48b325fb42436a01a.jpg: 640x640 2 machinerys, 8.8ms\nSpeed: 1.4ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-1037-_jpg.rf.c44151f7f28c4da9757409953b1bff55.jpg: 640x640 3 machinerys, 8.5ms\nSpeed: 1.4ms preprocess, 8.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-836_jpg.rf.df6fc9e569e7b6b850ecb75c37781d10.jpg: 640x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 2 vehicles, 8.3ms\nSpeed: 1.4ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/ppe_0064_jpg.rf.f019b082d09af2750a81ef5ea3fcbc3e.jpg: 640x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 8.3ms\nSpeed: 1.4ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.8889], device='cuda:0'), 'NO-Hardhat': tensor([0.5099], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.3334], device='cuda:0'), 'Person': tensor([0.9291], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.7623], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.7858], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9576], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.6643], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.8883], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.8692], device='cuda:0'), 'machinery': 0.0, 'vehicle': tensor([0.8423], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.7620], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.8193], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.8131], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.7799], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/-3154-_png_jpg.rf.f118da2b1c20afb78ff93dc7d558f42c.jpg: 640x640 1 Hardhat, 2 NO-Masks, 1 NO-Safety Vest, 1 Person, 8.4ms\nSpeed: 1.3ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/autox3_mp4-78_jpg.rf.dc5c00104c4cf733c2c06c820b82d338.jpg: 640x640 9 Safety Cones, 1 vehicle, 8.0ms\nSpeed: 1.4ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/-211-_png_jpg.rf.eac228e3993f9027795b6400262811e7.jpg: 640x640 2 Hardhats, 3 NO-Masks, 1 Person, 2 Safety Vests, 8.6ms\nSpeed: 1.4ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-226_jpg.rf.e6dcacf16dc2dbcfd29f6705b7c1a224.jpg: 640x640 1 Hardhat, 1 Person, 2 Safety Vests, 8.4ms\nSpeed: 1.3ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/IMG_3093_mp4-22_jpg.rf.ea118a6046b21e9246efd53599dfdc41.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 Person, 8.1ms\nSpeed: 1.4ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.9201], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.2922], device='cuda:0'), 'NO-Safety Vest': tensor([0.8299], device='cuda:0'), 'Person': tensor([0.8070], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': tensor([0.8757], device='cuda:0'), 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': tensor([0.8139], device='cuda:0')}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.8216], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': tensor([0.6622], device='cuda:0'), 'NO-Safety Vest': 0.0, 'Person': tensor([0.8634], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.8271], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.4372], device='cuda:0'), 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.7830], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': tensor([0.5574], device='cuda:0'), 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.8659], device='cuda:0'), 'NO-Hardhat': tensor([0.6659], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.8748], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"},{"name":"stderr","text":"image 1/1 /kaggle/input/godsensi/data/test/youtube-367_jpg.rf.fab8b016cb63c0928f40849db44ee98d.jpg: 640x640 3 machinerys, 8.7ms\nSpeed: 1.4ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/youtube-232_jpg.rf.f92f310106a11e01495ce8bfae0f9b5a.jpg: 640x640 1 Person, 8.2ms\nSpeed: 1.3ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/construction-1027-_jpg.rf.e78f55761814a8726ea51993407957af.jpg: 640x640 2 machinerys, 8.4ms\nSpeed: 1.4ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/IMG_3100_mp4-3_jpg.rf.f05ef399880b1ac30e900df4f2fbb3c0.jpg: 640x640 1 Hardhat, 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 8.7ms\nSpeed: 1.3ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n\nimage 1/1 /kaggle/input/godsensi/data/test/IMG_3103_mp4-8_jpg.rf.d54ebee33e6fd97c282258aabc1e52d7.jpg: 640x640 1 Mask, 1 NO-Safety Vest, 1 Person, 8.4ms\nSpeed: 1.4ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.9056], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': tensor([0.4806], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': tensor([0.6075], device='cuda:0'), 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': tensor([0.3318], device='cuda:0'), 'Mask': tensor([0.9143], device='cuda:0'), 'NO-Hardhat': tensor([0.5353], device='cuda:0'), 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.7167], device='cuda:0'), 'Person': tensor([0.9367], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n{'Hardhat': 0.0, 'Mask': 0.0, 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': 0.0, 'Person': 0.0, 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\nWaywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n{'Hardhat': 0.0, 'Mask': tensor([0.5110], device='cuda:0'), 'NO-Hardhat': 0.0, 'NO-Mask': 0.0, 'NO-Safety Vest': tensor([0.4779], device='cuda:0'), 'Person': tensor([0.9208], device='cuda:0'), 'Safety Cone': 0.0, 'Safety Vest': 0.0, 'machinery': 0.0, 'vehicle': 0.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:20:39.699227Z","iopub.execute_input":"2024-02-18T03:20:39.700326Z","iopub.status.idle":"2024-02-18T03:20:39.738684Z","shell.execute_reply.started":"2024-02-18T03:20:39.700285Z","shell.execute_reply":"2024-02-18T03:20:39.737661Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"         ID   Hardhat      Mask   NO-Hardhat   NO-Mask   NO-Safety Vest  \\\n0      ID_1  0.923418  0.000000     0.000000  0.803961         0.910405   \n1      ID_2  0.000000  0.000000     0.000000  0.000000         0.000000   \n2      ID_3  0.000000  0.896389     0.709123  0.000000         0.796589   \n3      ID_4  0.000000  0.000000     0.000000  0.000000         0.316987   \n4      ID_5  0.000000  0.000000     0.000000  0.000000         0.000000   \n..      ...       ...       ...          ...       ...              ...   \n191  ID_192  0.000000  0.000000     0.000000  0.000000         0.000000   \n192  ID_193  0.000000  0.000000     0.000000  0.000000         0.000000   \n193  ID_194  0.000000  0.000000     0.000000  0.000000         0.000000   \n194  ID_195  0.331814  0.914295     0.535347  0.000000         0.716660   \n195  ID_196  0.000000  0.511024     0.000000  0.000000         0.477893   \n\n       Person   Safety Cone   Safety Vest   machinery   vehicle  \\\n0    0.913449      0.000000      0.417002    0.000000  0.000000   \n1    0.327397      0.000000      0.000000    0.639019  0.861964   \n2    0.917995      0.000000      0.000000    0.000000  0.000000   \n3    0.940843      0.000000      0.000000    0.000000  0.000000   \n4    0.408148      0.734647      0.000000    0.000000  0.952296   \n..        ...           ...           ...         ...       ...   \n191  0.000000      0.000000      0.000000    0.905594  0.000000   \n192  0.480590      0.000000      0.000000    0.000000  0.000000   \n193  0.000000      0.000000      0.000000    0.607490  0.000000   \n194  0.936713      0.000000      0.000000    0.000000  0.000000   \n195  0.920794      0.000000      0.000000    0.000000  0.000000   \n\n                                              filename  \n0    006463_jpg.rf.02f19082420ecc5537b9d59abbe6050c...  \n1    youtube-34_jpg.rf.03eacc444bae3c5caa3fef5c736c...  \n2    IMG_0871_mp4-23_jpg.rf.03f872b1ed87ad7fadc85e0...  \n3    youtube-596_jpg.rf.11a8a4ac01d8aadb80eeb0406df...  \n4    ka_01181_png_jpg.rf.154ee4ef254eabd62e316be504...  \n..                                                 ...  \n191  youtube-367_jpg.rf.fab8b016cb63c0928f40849db44...  \n192  youtube-232_jpg.rf.f92f310106a11e01495ce8bfae0...  \n193  construction-1027-_jpg.rf.e78f55761814a8726ea5...  \n194  IMG_3100_mp4-3_jpg.rf.f05ef399880b1ac30e900df4...  \n195  IMG_3103_mp4-8_jpg.rf.d54ebee33e6fd97c282258aa...  \n\n[196 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Hardhat</th>\n      <th>Mask</th>\n      <th>NO-Hardhat</th>\n      <th>NO-Mask</th>\n      <th>NO-Safety Vest</th>\n      <th>Person</th>\n      <th>Safety Cone</th>\n      <th>Safety Vest</th>\n      <th>machinery</th>\n      <th>vehicle</th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID_1</td>\n      <td>0.923418</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.803961</td>\n      <td>0.910405</td>\n      <td>0.913449</td>\n      <td>0.000000</td>\n      <td>0.417002</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>006463_jpg.rf.02f19082420ecc5537b9d59abbe6050c...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID_2</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.327397</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.639019</td>\n      <td>0.861964</td>\n      <td>youtube-34_jpg.rf.03eacc444bae3c5caa3fef5c736c...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID_3</td>\n      <td>0.000000</td>\n      <td>0.896389</td>\n      <td>0.709123</td>\n      <td>0.000000</td>\n      <td>0.796589</td>\n      <td>0.917995</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>IMG_0871_mp4-23_jpg.rf.03f872b1ed87ad7fadc85e0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID_4</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.316987</td>\n      <td>0.940843</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>youtube-596_jpg.rf.11a8a4ac01d8aadb80eeb0406df...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID_5</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.408148</td>\n      <td>0.734647</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.952296</td>\n      <td>ka_01181_png_jpg.rf.154ee4ef254eabd62e316be504...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>ID_192</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.905594</td>\n      <td>0.000000</td>\n      <td>youtube-367_jpg.rf.fab8b016cb63c0928f40849db44...</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>ID_193</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.480590</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>youtube-232_jpg.rf.f92f310106a11e01495ce8bfae0...</td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>ID_194</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.607490</td>\n      <td>0.000000</td>\n      <td>construction-1027-_jpg.rf.e78f55761814a8726ea5...</td>\n    </tr>\n    <tr>\n      <th>194</th>\n      <td>ID_195</td>\n      <td>0.331814</td>\n      <td>0.914295</td>\n      <td>0.535347</td>\n      <td>0.000000</td>\n      <td>0.716660</td>\n      <td>0.936713</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>IMG_3100_mp4-3_jpg.rf.f05ef399880b1ac30e900df4...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>ID_196</td>\n      <td>0.000000</td>\n      <td>0.511024</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.477893</td>\n      <td>0.920794</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>IMG_3103_mp4-8_jpg.rf.d54ebee33e6fd97c282258aa...</td>\n    </tr>\n  </tbody>\n</table>\n<p>196 rows Ã— 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"for index, row in submission.iterrows():\n    results = model.predict(conf=0.3,source=os.path.join(INPUT_DIR, 'test', row['filename']), save=True)\n    object_names = []\n    for result in results:\n        if result.boxes:\n            for i in result.boxes.cls:\n                class_id = int(i)\n                object_name = model.names[class_id]\n                object_names.append(object_name)\n        print('Waywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa')\n        \n        object_names = list(set(object_names))\n        print(object_names)\n    for class_name in object_names:\n        submission.loc[index, \" \"+class_name] = 1\n\nsubmission.fillna(0, inplace=True)\nprint(submission.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.drop(['filename'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:20:55.289251Z","iopub.execute_input":"2024-02-18T03:20:55.290265Z","iopub.status.idle":"2024-02-18T03:20:55.296527Z","shell.execute_reply.started":"2024-02-18T03:20:55.290223Z","shell.execute_reply":"2024-02-18T03:20:55.295481Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submissionnyoo.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:21:04.520963Z","iopub.execute_input":"2024-02-18T03:21:04.521861Z","iopub.status.idle":"2024-02-18T03:21:04.536625Z","shell.execute_reply.started":"2024-02-18T03:21:04.521808Z","shell.execute_reply":"2024-02-18T03:21:04.535374Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Define the columns you want to keep\ncolumns_to_keep = ['ID']+classes\n\n# Create a new DataFrame with only the specified columns\nextracted_submission = submission[columns_to_keep]\n\n# Write the DataFrame to a CSV file\nextracted_submission.to_csv('SubmissionBest14.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### yoyo","metadata":{}},{"cell_type":"code","source":"d = {0: ' Hardhat',\n 1: ' Mask',\n 2: ' NO-Hardhat',\n 3: ' NO-Mask',\n 4: ' NO-Safety Vest',\n 5: ' Person',\n 6: ' Safety Cone',\n 7: ' Safety Vest',\n 8: ' machinery',\n 9: ' vehicle'}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/godsensi/Test.csv')\ntest.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss=pd.read_csv(\"/kaggle/input/godsensi/SampleSubmission.csv\")\nss.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = test['filename'].tolist()\ntest_ids = test['ID'].tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(test_images)  # Assuming test_images is a list of image paths\n\nfor res in predictions:\n    probabilities = res[0].scores.tolist()  # Assuming res[0].scores contains class probabilities\n    classes = [d[i] for i in res[0].boxes.cls.tolist()]  # Assuming d is the class mapping dictionary\n    # Initialize all probabilities to 0\n    prob_dict = {class_name: 0 for class_name in ['Hardhat', 'Mask', 'NO-Hardhat', 'NO-Mask', 'NO-Safety Vest', 'Person', 'Safety Cone', 'Safety Vest', 'machinery', 'vehicle']}\n    \n    # Update probabilities for detected classes\n    for prob, class_name in zip(probabilities, classes):\n        prob_dict[class_name] = prob\n    \n    # Append the probabilities to respective lists\n    Hardhat.append(prob_dict['Hardhat'])\n    Mask.append(prob_dict['Mask'])\n    NO_Hardhat.append(prob_dict['NO-Hardhat'])\n    NO_Mask.append(prob_dict['NO-Mask'])\n    NO_Safety_Vest.append(prob_dict['NO-Safety Vest'])\n    Person.append(prob_dict['Person'])\n    Safety_Cone.append(prob_dict['Safety Cone'])\n    Safety_Vest.append(prob_dict['Safety Vest'])\n    machinery.append(prob_dict['machinery'])\n    vehicle.append(prob_dict['vehicle'])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Hardhat = []\nMask = []\nNO_Hardhat = []\nNO_Mask = []\nNO_Safety_Vest = [] \nPerson = []\nSafety_Cone = []\nSafety_Vest = []\nmachinery = []\nvehicle = []\nfor image in test_images:\n    res = model.predict(f\"/kaggle/input/godsensi/data/test/{image}\")\n    #res= model.predict(source=os.path.join(INPUT_DIR, 'test'), save=True)\n    l  = list(set([int(i) for i in res[0].boxes.cls.tolist()]))\n    response = [d[i] for i in l]\n    if ' Hardhat' in response:\n        Hardhat.append(1)\n    else:\n        Hardhat.append(0)\n    if ' Mask' in response:\n        Mask.append(1)\n    else:\n        Mask.append(0)\n    if ' NO-Hardhat' in response:\n        NO_Hardhat.append(1)\n    else:\n        NO_Hardhat.append(0)\n    if ' NO-Mask' in response:\n        NO_Mask.append(1)\n    else:\n        NO_Mask.append(0)\n    if ' NO-Safety Vest' in response:\n        NO_Safety_Vest.append(1)\n    else:\n        NO_Safety_Vest.append(0)\n    if ' Person' in response:\n        Person.append(1)\n    else:\n        Person.append(0)\n    if ' Safety Cone' in response:\n        Safety_Cone.append(1)\n    else:\n        Safety_Cone.append(0)\n    if ' Safety Vest' in response:\n        Safety_Vest.append(1)\n    else:\n        Safety_Vest.append(0)\n    if ' machinery' in response:\n        machinery.append(1)\n    else:\n        machinery.append(0)\n    if 'vehicle' in response:\n        vehicle.append(1)\n    else:\n        vehicle.append(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss=pd.read_csv(\"/kaggle/input/godsensi/SampleSubmission.csv\")\nss.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'ID': test_ids, ' Hardhat': Hardhat, ' Mask': Mask, ' NO-Hardhat': NO_Hardhat, ' NO-Mask': NO_Mask, ' NO-Safety Vest': NO_Safety_Vest, ' Person': Person, ' Safety Cone': Safety_Cone, ' Safety Vest': Safety_Vest, ' machinery': machinery, ' vehicle': vehicle})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submissionnn-43.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h4 style=\"border-bottom: 3px solid #FAD7A0; padding: 12px 12px; font-family: Sans-Serif; color:black\">\n<b>Make predicitons on test set</b></h4>","metadata":{}},{"cell_type":"code","source":"results = model.predict(source=os.path.join(INPUT_DIR, 'test', 'images'), save=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h4 style=\"border-bottom: 3px solid #FAD7A0; padding: 12px 12px; font-family: Sans-Serif; color:black\">\n<b>Show prediction results</b></h4>","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\n\npredicitions = glob.glob(os.path.join(WORK_DIR, 'runs/detect/predict2', '*'))\n\nn = 10\n\nfor i in range(n):\n    idx = np.random.randint(0, len(predicitions))\n    image = Image.open(predicitions[idx])\n    plt.imshow(image)\n    plt.grid(False)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}